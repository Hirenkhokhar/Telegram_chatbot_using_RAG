{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T10:49:55.843871Z",
     "iopub.status.busy": "2025-02-14T10:49:55.843514Z",
     "iopub.status.idle": "2025-02-14T10:49:55.856306Z",
     "shell.execute_reply": "2025-02-14T10:49:55.855402Z",
     "shell.execute_reply.started": "2025-02-14T10:49:55.843841Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T10:47:41.209715Z",
     "iopub.status.busy": "2025-02-14T10:47:41.209438Z",
     "iopub.status.idle": "2025-02-14T10:47:41.215120Z",
     "shell.execute_reply": "2025-02-14T10:47:41.214338Z",
     "shell.execute_reply.started": "2025-02-14T10:47:41.209694Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "loader = TextLoader(\"/kaggle/input/india/india.txt\")\n",
    "Documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T10:50:05.348928Z",
     "iopub.status.busy": "2025-02-14T10:50:05.348639Z",
     "iopub.status.idle": "2025-02-14T10:50:05.355159Z",
     "shell.execute_reply": "2025-02-14T10:50:05.354064Z",
     "shell.execute_reply.started": "2025-02-14T10:50:05.348906Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size= 500, chunk_overlap= 150)\n",
    "texts = text_splitter.split_documents(Documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T10:48:08.713724Z",
     "iopub.status.busy": "2025-02-14T10:48:08.713407Z",
     "iopub.status.idle": "2025-02-14T10:48:36.504942Z",
     "shell.execute_reply": "2025-02-14T10:48:36.504250Z",
     "shell.execute_reply.started": "2025-02-14T10:48:08.713699Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-d1c08a305f01>:2: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedings = HuggingFaceEmbeddings()\n",
      "<ipython-input-12-d1c08a305f01>:2: LangChainDeprecationWarning: Default values for HuggingFaceEmbeddings.model_name were deprecated in LangChain 0.2.16 and will be removed in 0.4.0. Explicitly pass a model_name to the HuggingFaceEmbeddings constructor instead.\n",
      "  embedings = HuggingFaceEmbeddings()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed9b08f79b8d4ce98fbe383b6b52a406",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3595180cab8640638cd156164ee3743c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7fbe5997f1646e68e27cee5a0087d8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "429c6492bd3741b18f4de959262ee278",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "124073104ca34fafb31752c765759c30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d83d4451b52d49ecb54c558845c2da30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c9e0c07acfe403396843bdaf5e4481a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b039db165e7b4138b81e38b05e06e5c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d411002376d406ba9a3f5ea506a3eee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc7acac8d762419aaa50a3003768af0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48d2316da47749eaa39860756f454e9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling%2Fconfig.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "persist_directory = \"db\"\n",
    "embedings = HuggingFaceEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T10:50:20.050158Z",
     "iopub.status.busy": "2025-02-14T10:50:20.049829Z",
     "iopub.status.idle": "2025-02-14T10:50:22.037874Z",
     "shell.execute_reply": "2025-02-14T10:50:22.037184Z",
     "shell.execute_reply.started": "2025-02-14T10:50:20.050118Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "vectordb = Chroma.from_documents(documents=texts,\n",
    "                                 embedding=embedings,\n",
    "                                 persist_directory=persist_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T10:50:47.473751Z",
     "iopub.status.busy": "2025-02-14T10:50:47.473459Z",
     "iopub.status.idle": "2025-02-14T10:50:47.478283Z",
     "shell.execute_reply": "2025-02-14T10:50:47.477253Z",
     "shell.execute_reply.started": "2025-02-14T10:50:47.473728Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-d832e715b29a>:1: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  vectordb.persist()\n"
     ]
    }
   ],
   "source": [
    "vectordb.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T10:51:03.506643Z",
     "iopub.status.busy": "2025-02-14T10:51:03.506344Z",
     "iopub.status.idle": "2025-02-14T10:51:03.516457Z",
     "shell.execute_reply": "2025-02-14T10:51:03.515529Z",
     "shell.execute_reply.started": "2025-02-14T10:51:03.506620Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-18-a1c60508a432>:1: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vectordb = Chroma(persist_directory=persist_directory,\n"
     ]
    }
   ],
   "source": [
    "vectordb = Chroma(persist_directory=persist_directory,\n",
    "                  embedding_function=embedings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T10:51:24.681291Z",
     "iopub.status.busy": "2025-02-14T10:51:24.680925Z",
     "iopub.status.idle": "2025-02-14T10:51:24.685033Z",
     "shell.execute_reply": "2025-02-14T10:51:24.684200Z",
     "shell.execute_reply.started": "2025-02-14T10:51:24.681260Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from langchain.llms import HuggingFaceHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T10:51:40.578542Z",
     "iopub.status.busy": "2025-02-14T10:51:40.578169Z",
     "iopub.status.idle": "2025-02-14T10:51:40.582580Z",
     "shell.execute_reply": "2025-02-14T10:51:40.581505Z",
     "shell.execute_reply.started": "2025-02-14T10:51:40.578517Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "retriever = vectordb.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T10:51:57.509752Z",
     "iopub.status.busy": "2025-02-14T10:51:57.509434Z",
     "iopub.status.idle": "2025-02-14T10:51:57.613823Z",
     "shell.execute_reply": "2025-02-14T10:51:57.613174Z",
     "shell.execute_reply.started": "2025-02-14T10:51:57.509726Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "llm = HuggingFaceHub(repo_id=\"meta-llama/Meta-Llama-3-8B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T10:52:11.600373Z",
     "iopub.status.busy": "2025-02-14T10:52:11.600026Z",
     "iopub.status.idle": "2025-02-14T10:52:11.692375Z",
     "shell.execute_reply": "2025-02-14T10:52:11.691391Z",
     "shell.execute_reply.started": "2025-02-14T10:52:11.600348Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "llm = HuggingFaceHub(repo_id=\"meta-llama/Meta-Llama-3-8B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T10:52:19.631751Z",
     "iopub.status.busy": "2025-02-14T10:52:19.631450Z",
     "iopub.status.idle": "2025-02-14T10:52:19.637305Z",
     "shell.execute_reply": "2025-02-14T10:52:19.636586Z",
     "shell.execute_reply.started": "2025-02-14T10:52:19.631728Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuggingFaceHub(client=<InferenceClient(model='meta-llama/Meta-Llama-3-8B-Instruct', timeout=None)>, repo_id='meta-llama/Meta-Llama-3-8B-Instruct', task='text-generation')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T10:52:28.589529Z",
     "iopub.status.busy": "2025-02-14T10:52:28.589196Z",
     "iopub.status.idle": "2025-02-14T10:52:28.671205Z",
     "shell.execute_reply": "2025-02-14T10:52:28.670506Z",
     "shell.execute_reply.started": "2025-02-14T10:52:28.589505Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T10:52:39.190625Z",
     "iopub.status.busy": "2025-02-14T10:52:39.190322Z",
     "iopub.status.idle": "2025-02-14T10:52:39.194504Z",
     "shell.execute_reply": "2025-02-14T10:52:39.193580Z",
     "shell.execute_reply.started": "2025-02-14T10:52:39.190596Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "template_1 = \"\"\"Given the following context and a question, generate an answer based on this context only.\n",
    "In the answer try to provide as much as text as possible from \"response\" section in the source documents.\n",
    "If the answer is not found in the context, kindly state \"I don't know.\" Don't try to make up an answer.\n",
    "Question: {question}\n",
    "\n",
    "context : {context}\n",
    "\n",
    "Response:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T10:52:48.160428Z",
     "iopub.status.busy": "2025-02-14T10:52:48.160062Z",
     "iopub.status.idle": "2025-02-14T10:52:48.164584Z",
     "shell.execute_reply": "2025-02-14T10:52:48.163776Z",
     "shell.execute_reply.started": "2025-02-14T10:52:48.160401Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "prompt=ChatPromptTemplate.from_template(template_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T10:52:55.630424Z",
     "iopub.status.busy": "2025-02-14T10:52:55.630077Z",
     "iopub.status.idle": "2025-02-14T10:52:55.636795Z",
     "shell.execute_reply": "2025-02-14T10:52:55.635980Z",
     "shell.execute_reply.started": "2025-02-14T10:52:55.630399Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.schema.output_parser import StrOutputParser "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T10:53:03.746646Z",
     "iopub.status.busy": "2025-02-14T10:53:03.746332Z",
     "iopub.status.idle": "2025-02-14T10:53:03.750692Z",
     "shell.execute_reply": "2025-02-14T10:53:03.749817Z",
     "shell.execute_reply.started": "2025-02-14T10:53:03.746622Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "output_parser = StrOutputParser() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T10:53:10.934207Z",
     "iopub.status.busy": "2025-02-14T10:53:10.933889Z",
     "iopub.status.idle": "2025-02-14T10:53:10.938565Z",
     "shell.execute_reply": "2025-02-14T10:53:10.937482Z",
     "shell.execute_reply.started": "2025-02-14T10:53:10.934181Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "rag_chain = (\n",
    "    {\"context\": retriever,  \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | output_parser\n",
    ")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T10:53:20.438431Z",
     "iopub.status.busy": "2025-02-14T10:53:20.438082Z",
     "iopub.status.idle": "2025-02-14T10:53:24.597119Z",
     "shell.execute_reply": "2025-02-14T10:53:24.596182Z",
     "shell.execute_reply.started": "2025-02-14T10:53:20.438403Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Given the following context and a question, generate an answer based on this context only.\n",
      "In the answer try to provide as much as text as possible from \"response\" section in the source documents.\n",
      "If the answer is not found in the context, kindly state \"I don't know.\" Don't try to make up an answer.\n",
      "Question:  give me indian history in brief?\n",
      "\n",
      "context : [Document(metadata={'source': '/kaggle/input/india/india.txt'}, page_content='Historical Background\\nThe history of India is as vast and diverse as the country itself, dating back to the Indus Valley Civilization (circa 3300–1300 BCE), one of the world’s earliest urban societies. It was marked by advanced town planning, complex social structures, and trade networks extending to Mesopotamia.'), Document(metadata={'source': '/kaggle/input/india/india.txt'}, page_content='India, officially the Republic of India, is one of the oldest civilizations and a dynamic player on the global stage today. The country’s unique geographical features, cultural diversity, historical importance, and rapidly growing economy have made it a nation of great interest. With over 1.4 billion people, India is the most populous country in the world, contributing significantly to global politics, trade, and culture. This essay explores India in various aspects, including its historical'), Document(metadata={'source': '/kaggle/input/india/india.txt'}, page_content='the world, contributing significantly to global politics, trade, and culture. This essay explores India in various aspects, including its historical evolution, geography, culture, economic progress, and the challenges it faces.'), Document(metadata={'source': '/kaggle/input/india/india.txt'}, page_content='The British colonial period brought significant changes to Indian society, economy, and infrastructure. While the British built railways, canals, and telegraph systems, they also drained India’s wealth and resources to benefit their empire. The discontent among Indians led to the rise of the Indian National Congress (INC) in 1885, which spearheaded the fight for independence.')]\n",
      "\n",
      "Response: The history of India is as vast and diverse as the country itself, dating back to the Indus Valley Civilization (circa 3300–1300 BCE), one of the world’s earliest urban societies. It was marked by advanced town planning, complex social structures, and trade networks extending to Mesopotamia. The British colonial period brought significant changes to Indian society, economy, and infrastructure. While the British built railways, canals, and telegraph systems, they also drained India’s wealth and resources to benefit their empire. The discontent among Indians led to the rise of the Indian National Congress (INC) in 1885, which spearheaded the fight for independence.\n"
     ]
    }
   ],
   "source": [
    "query=\" give me indian history in brief?\"\n",
    "results = rag_chain.invoke(query)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T10:53:41.534985Z",
     "iopub.status.busy": "2025-02-14T10:53:41.534657Z",
     "iopub.status.idle": "2025-02-14T10:53:42.241172Z",
     "shell.execute_reply": "2025-02-14T10:53:42.240360Z",
     "shell.execute_reply.started": "2025-02-14T10:53:41.534958Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Given the following context and a question, generate an answer based on this context only.\n",
      "In the answer try to provide as much as text as possible from \"response\" section in the source documents.\n",
      "If the answer is not found in the context, kindly state \"I don't know.\" Don't try to make up an answer.\n",
      "Question: give me name indian prime Minister?\n",
      "\n",
      "context : [Document(metadata={'source': '/kaggle/input/india/india.txt'}, page_content='Post-Independence Era\\nAfter independence, India adopted a democratic system of government, with Jawaharlal Nehru becoming its first Prime Minister. The Constitution of India, enacted in 1950, established India as a sovereign, socialist, secular, and democratic republic. The constitution is the longest written constitution in the world and lays down the framework for the country’s political, legal, and social institutions.'), Document(metadata={'source': '/kaggle/input/india/india.txt'}, page_content='Economic Liberalization and Growth\\nIndia’s economy remained largely socialist and state-controlled until the early 1990s, when a severe balance of payments crisis forced the government to implement sweeping economic reforms. In 1991, under the leadership of Prime Minister P.V. Narasimha Rao and Finance Minister Manmohan Singh, India began liberalizing its economy, reducing tariffs, deregulating industries, and encouraging foreign investment.'), Document(metadata={'source': '/kaggle/input/india/india.txt'}, page_content=\"The early 20th century saw the emergence of Mahatma Gandhi, who became the face of the Indian independence movement. Gandhi's philosophy of non-violence and civil disobedience rallied millions of Indians to oppose British rule peacefully. Other leaders like Jawaharlal Nehru, Subhas Chandra Bose, and Sardar Vallabhbhai Patel played crucial roles in the movement.\"), Document(metadata={'source': '/kaggle/input/india/india.txt'}, page_content='India, officially the Republic of India, is one of the oldest civilizations and a dynamic player on the global stage today. The country’s unique geographical features, cultural diversity, historical importance, and rapidly growing economy have made it a nation of great interest. With over 1.4 billion people, India is the most populous country in the world, contributing significantly to global politics, trade, and culture. This essay explores India in various aspects, including its historical')]\n",
      "\n",
      "Response: The current Prime Minister of India is Narendra Modi.\n"
     ]
    }
   ],
   "source": [
    "query_1=\"give me name indian prime Minister?\"\n",
    "print(rag_chain.invoke(query_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-02-14T11:02:49.032Z",
     "iopub.execute_input": "2025-02-14T10:54:36.270896Z",
     "iopub.status.busy": "2025-02-14T10:54:36.270472Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import telebot\n",
    "bot = telebot.TeleBot('7546573610:AAFu59llvjtCXhpT4_tb3c3ZDlyovVTNBjg')\n",
    "\n",
    "@bot.message_handler(func=lambda message: True)\n",
    "def handle_message(message):\n",
    "    query = message.text\n",
    "    response = rag_chain.invoke(query)\n",
    "    bot.reply_to(message, response)\n",
    "\n",
    "bot.polling() "
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 5668044,
     "sourceId": 9350652,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6666229,
     "sourceId": 10748694,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30887,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
